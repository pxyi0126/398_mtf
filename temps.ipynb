{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.652554Z",
     "start_time": "2019-10-31T23:36:27.180520Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import plotly.express as px\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "\n",
    "from lec_utils import * \n",
    "# from save_data import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Title Here\n",
    "\n",
    "**Name(s)**: Pheobe Yi and Omkar nayak \n",
    "\n",
    "**Website Link**: In progress "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year 2000...\n",
      "[PosixPath('/Users/yipho/eecs398/portfolio/datanew/ICPSR_03184-2000')]\n",
      "Found Form 1 and Form 6 data for year 2000.\n",
      "Loaded Form 1 with shape: (13286, 108)\n",
      "Renamed 'CASEID' to 'RESPONDENT_ID'.\n",
      "Loaded Form 6 with shape: (2197, 310)\n",
      "Renamed 'CASEID' to 'RESPONDENT_ID'.\n",
      "Merged data shape: (2197, 417)\n",
      "Saved merged data for year 2000 to /Users/yipho/eecs398/portfolio/rawdata/ICPSR_data_2000.csv\n",
      "Processing year 2001...\n",
      "[]\n",
      "No ICPSR folder found for year 2001. Skipping...\n",
      "Processing year 2002...\n",
      "[]\n",
      "No ICPSR folder found for year 2002. Skipping...\n",
      "Processing year 2003...\n",
      "[]\n",
      "No ICPSR folder found for year 2003. Skipping...\n",
      "Processing year 2004...\n",
      "[]\n",
      "No ICPSR folder found for year 2004. Skipping...\n",
      "Processing year 2005...\n",
      "[]\n",
      "No ICPSR folder found for year 2005. Skipping...\n",
      "Processing year 2006...\n",
      "[]\n",
      "No ICPSR folder found for year 2006. Skipping...\n",
      "Processing year 2007...\n",
      "[]\n",
      "No ICPSR folder found for year 2007. Skipping...\n",
      "Processing year 2008...\n",
      "[]\n",
      "No ICPSR folder found for year 2008. Skipping...\n",
      "Processing year 2009...\n",
      "[]\n",
      "No ICPSR folder found for year 2009. Skipping...\n",
      "Processing year 2010...\n",
      "[]\n",
      "No ICPSR folder found for year 2010. Skipping...\n",
      "Processing year 2011...\n",
      "[]\n",
      "No ICPSR folder found for year 2011. Skipping...\n",
      "Processing year 2012...\n",
      "[]\n",
      "No ICPSR folder found for year 2012. Skipping...\n",
      "Processing year 2013...\n",
      "[]\n",
      "No ICPSR folder found for year 2013. Skipping...\n",
      "Processing year 2014...\n",
      "[]\n",
      "No ICPSR folder found for year 2014. Skipping...\n",
      "Processing year 2015...\n",
      "[]\n",
      "No ICPSR folder found for year 2015. Skipping...\n",
      "Processing year 2016...\n",
      "[]\n",
      "No ICPSR folder found for year 2016. Skipping...\n",
      "Processing year 2017...\n",
      "[]\n",
      "No ICPSR folder found for year 2017. Skipping...\n",
      "Processing year 2018...\n",
      "[]\n",
      "No ICPSR folder found for year 2018. Skipping...\n",
      "Processing year 2019...\n",
      "[]\n",
      "No ICPSR folder found for year 2019. Skipping...\n",
      "Processing year 2020...\n",
      "[]\n",
      "No ICPSR folder found for year 2020. Skipping...\n",
      "Processing year 2021...\n",
      "[]\n",
      "No ICPSR folder found for year 2021. Skipping...\n",
      "Processing year 2022...\n",
      "[]\n",
      "No ICPSR folder found for year 2022. Skipping...\n",
      "Processing year 2023...\n",
      "[PosixPath('/Users/yipho/eecs398/portfolio/datanew/ICPSR_39172-2023')]\n",
      "Found Form 1 and Form 6 data for year 2023.\n",
      "Loaded Form 1 with shape: (7584, 198)\n",
      "Loaded Form 6 with shape: (1281, 374)\n",
      "Merged data shape: (1281, 571)\n",
      "Saved merged data for year 2023 to /Users/yipho/eecs398/portfolio/rawdata/ICPSR_data_2023.csv\n"
     ]
    }
   ],
   "source": [
    "base_path = Path(\"/Users/yipho/eecs398/portfolio/datanew\")\n",
    "output_path = Path(\"/Users/yipho/eecs398/portfolio/rawdata\") \n",
    "output_path.mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "years_to_process = range(2000, 2024)\n",
    "\n",
    "def rename_case_id_to_respondent_id(df):\n",
    "    if \"CASEID\" in df.columns:\n",
    "        df.rename(columns={\"CASEID\": \"RESPONDENT_ID\"}, inplace=True)\n",
    "    return df\n",
    "\n",
    "def load_and_save_icpsr_data(base_path, output_path, years_to_process):\n",
    "    for year in years_to_process:\n",
    "        print(f\"Processing year {year}...\")\n",
    "\n",
    "        icpsr_folders = list(base_path.glob(f\"ICPSR_*{year}\")) \n",
    "        print(icpsr_folders)\n",
    "        \n",
    "        if not icpsr_folders:\n",
    "            print(f\"No ICPSR folder found for year {year}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        merged_data= []  \n",
    "\n",
    "        for folder in icpsr_folders:\n",
    "            study_number = folder.name.split(\"_\")[1].split(\"-\")[0]  \n",
    "\n",
    "            form1_path = folder / f\"DS0001/{study_number}-0001-Data.dta\"\n",
    "            form6_path = folder / f\"DS0006/{study_number}-0006-Data.dta\"\n",
    "\n",
    "            # Load and merge Form 1 and Form 6 if both exist\n",
    "            if form1_path.exists() and form6_path.exists():\n",
    "                # print(f\"Found Form 1 and Form 6 data for year {year}.\")\n",
    "                try:\n",
    "                    # Load Form 1\n",
    "                    df1 = pd.read_stata(form1_path)\n",
    "                    print(f\"Loaded Form 1 with shape: {df1.shape}\")\n",
    "                    df1 = rename_case_id_to_respondent_id(df1)\n",
    "\n",
    "                    # Load Form 6\n",
    "                    df6 = pd.read_stata(form6_path)\n",
    "                    print(f\"Loaded Form 6 with shape: {df6.shape}\")\n",
    "                    df6 = rename_case_id_to_respondent_id(df6)\n",
    "\n",
    "  \n",
    "                    if \"RESPONDENT_ID\" in df1.columns and \"RESPONDENT_ID\" in df6.columns:\n",
    "                        df_merged = df1.merge(df6, on=\"RESPONDENT_ID\", how=\"inner\")\n",
    "                        print(f\"Merged data shape: {df_merged.shape}\")\n",
    "\n",
    "\n",
    "                        df_merged[\"Year\"] = year\n",
    "\n",
    "                        merged_data.append(df_merged)\n",
    "                    else:\n",
    "                        print(f\"'RESPONDENT_ID' column missing in Form 1 or Form 6 for year {year}. Skipping merge.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing Form 1 and Form 6 for {year}: {e}\")\n",
    "            else:\n",
    "                if not form1_path.exists():\n",
    "                    print(f\"Form 1 data not found for year {year}: {form1_path}\")\n",
    "                if not form6_path.exists():\n",
    "                    print(f\"Form 6 data not found for year {year}: {form6_path}\")\n",
    "\n",
    "        if merged_data:\n",
    "            year_df = pd.concat(merged_data, axis=0)  \n",
    "            output_file = output_path / f\"ICPSR_data_{year}.csv\"\n",
    "            year_df.to_csv(output_file, index=False)\n",
    "            print(f\"Saved merged data for year {year} to {output_file}\")\n",
    "        else:\n",
    "            print(f\"No merged data found for year {year}.\")\n",
    "\n",
    "\n",
    "load_and_save_icpsr_data(base_path, output_path, years_to_process)\n",
    "#god bless Kerby Shedden "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_interest = ['RESPONDENT_ID', 'V1_x', 'V2150','V49_x', 'V2167', 'V2157', 'V2155', 'V2156', 'V5313', 'V5321']\n",
    "dfmain = dfcat[cols_interest]\n",
    "dfmain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_clean = ['V49_x','V2150', 'V2167', 'V2157', 'V2155', 'V2156', 'V5313', 'V5321']\n",
    "\n",
    "def extract_number(column):\n",
    "    pattern = r\".+:\\s*\\((\\d+)\\)\"\n",
    "    return column.apply(lambda x: int(re.match(pattern, str(x)).group(1)) if re.match(pattern, str(x)) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols_clean:\n",
    "    dfmain[col] = extract_number(dfcat[col])\n",
    "\n",
    "dfmain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop 6,8,-9 for 2167 Pol leaning \n",
    "dfmain = dfmain[dfmain['V2167'] != 6]\n",
    "dfmain = dfmain[dfmain['V2167'] != 8]\n",
    "dfmain = dfmain[dfmain['V2167'] != -9]\n",
    "#drop nan\n",
    "dfmain = dfmain.dropna(subset=['V2167'])\n",
    "#rescale and regularize \n",
    "dfmain['V2167'] = dfmain['V2167'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sex, drop -9, 3 and 4 (missing other and refused to answer)\n",
    "dfmain = dfmain[dfmain['V2150'] != -9]\n",
    "dfmain = dfmain[dfmain['V2150'] != 4]\n",
    "dfmain = dfmain[dfmain['V2150'] != 3]\n",
    "\n",
    "dfmain = dfmain.dropna(subset=['V2150'])\n",
    "\n",
    "dfmain['V2150'] = dfmain['V2150'] - 1\n",
    "# 0 for male, 1 for female now \n",
    "dfmain['V2150'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_blfs = [\"Very Conservative\", \"Conservative\", \"Moderate\", \"Liberal\", \"Very Liberal\"]\n",
    "counts = dfmain['V2167'].value_counts().sort_index()\n",
    "\n",
    "\n",
    "colors = ['red', 'pink', 'darkgray', 'lightblue', 'blue']\n",
    "\n",
    "\n",
    "fig = px.bar(\n",
    "    x=counts.index,\n",
    "    y=counts.values,\n",
    "    title='Political Beliefs Distribution',\n",
    "    labels={'x': 'Political Beliefs', 'y': 'Count'},\n",
    "    color=counts.index, \n",
    "    color_discrete_sequence=colors  \n",
    ")\n",
    "\n",
    "# Update x-axis labels\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Political Beliefs\",\n",
    "    yaxis_title=\"Count\",\n",
    "    xaxis=dict(\n",
    "        tickmode='array',\n",
    "        tickvals=counts.index,\n",
    "        ticktext=pol_blfs\n",
    "    )\n",
    ")\n",
    "# Show the chart\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"fuck this man why isn't it working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Framing a Prediction Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.657068Z",
     "start_time": "2019-10-31T23:36:28.654650Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
